# DataEngineerRoadMap
This repository will summarise the road map from beginning to job acquire 

1- Learn Computer science fundemantals, a free resource is https://www.youtube.com/watch?v=IDDmrzzB14M&list=PLhQjrBD2T380F_inVRXMIHCqLaNUd7bN4
2- Learn a language either python java or scala 
3- SQL Structured Query Language should be in expert level as it would be used in day to day frequency.
4- Read a book called Fundamental of Data Engineering Plan and Build Robust Data System by Joe Reis
5- Learn Data Warehouse which consist of a two parts 
 a) Learning about core Data Warehouse fundamentals (that don’t change): It includes learning about OLAP vs OLTP, Dimension Table, Extract Transform Load, ER Modeling, or Dimension Modelling such as understanding fact and dimension tables
 b)Learning about important tools that are available in the market: Snowflake, BigQuery, Redshift, Synapse Analytics
I suggest you start with Snowflake, it’s a modern data warehouse tool, and lots of companies are migrating to Snowflake
6- Learn Data Processing,This is the central part of data engineering, you get data from multiple places like applications, web analytics, and sensors, all of these data are in different formats, coming at a different frequency so you need proper tools to process them

There are two main frameworks:
— Batch processing: Processing data in batches, such as processing last month’s data once or twice a day.
— Real-time processing: Processing data as it comes in, in real-time.

For batch processing, most companies use Apache Spark. It’s an open-source framework for data processing. You can start by learning Apache Spark fundamentals, and then learn a tool that powers the Apache Spark environment, such as Databricks, AWS EMR, GCP Data Proc, or any other tools you find in the market.

My suggestion is to practice with Spark on Databrick and use PySpark (Python) as the language. 
For real-time processing, we have frameworks and tools such as Apache Kafka, Apache Flink, and Apache Storm. You can pick one and learn about it.
7- Open Table Formats 
8- Learn cloud provider in fundamentals level aws azure o google cloud
9-Learn Docker and Kubernetes which are useful when deploying data pipelines in production.
10- Reading customer case studies on platforms such as AWS and GCP can give you a better understanding of how to use these tools in real-world scenarios.
